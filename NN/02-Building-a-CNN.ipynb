{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Building-a-CNN\" data-toc-modified-id=\"Building-a-CNN-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Building a CNN</a></div><div class=\"lev2 toc-item\"><a href=\"#Prepare-the-dataset\" data-toc-modified-id=\"Prepare-the-dataset-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Prepare the dataset</a></div><div class=\"lev2 toc-item\"><a href=\"#Building-the-CNN\" data-toc-modified-id=\"Building-the-CNN-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Building the CNN</a></div><div class=\"lev2 toc-item\"><a href=\"#Fitting-the-CNN-to-the-images\" data-toc-modified-id=\"Fitting-the-CNN-to-the-images-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Fitting the CNN to the images</a></div><div class=\"lev2 toc-item\"><a href=\"#Making-new-predictions\" data-toc-modified-id=\"Making-new-predictions-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Making new predictions</a></div><div class=\"lev2 toc-item\"><a href=\"#Challenge\" data-toc-modified-id=\"Challenge-15\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Challenge</a></div><div class=\"lev2 toc-item\"><a href=\"#Better-solution\" data-toc-modified-id=\"Better-solution-16\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Better solution</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a CNN\n",
    "\n",
    "Credit: [Deep Learning A-Zâ„¢: Hands-On Artificial Neural Networks](https://www.udemy.com/deeplearning/learn/v4/content)\n",
    "\n",
    "- [Getting the dataset](https://www.superdatascience.com/deep-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prepare the dataset\n",
    "\n",
    "- keras has an efficient support for images, but we need to prepare all the images in a special structure:\n",
    "    - Separate images in training and test folder.\n",
    "    - In order to differentiate the class labels, the simple trick is to make two different folders: one for dog and one for cat. Keras will understand how to differentiate the labels of our independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find: warning: you have specified the -maxdepth option after a non-option argument -type, but options are not positional (-maxdepth affects tests specified before it as well as those specified after it).  Please specify options before other arguments.\r\n",
      "\r\n",
      "./Convolutional_Neural_Networks/dataset\r\n",
      "./Convolutional_Neural_Networks/dataset/training_set\r\n",
      "./Convolutional_Neural_Networks/dataset/training_set/dogs\r\n",
      "./Convolutional_Neural_Networks/dataset/training_set/cats\r\n",
      "./Convolutional_Neural_Networks/dataset/test_set\r\n",
      "./Convolutional_Neural_Networks/dataset/test_set/dogs\r\n",
      "./Convolutional_Neural_Networks/dataset/test_set/cats\r\n",
      "./Convolutional_Neural_Networks/dataset/single_prediction\r\n"
     ]
    }
   ],
   "source": [
    "# List all directories and sub-directories\n",
    "!find ./Convolutional_Neural_Networks/dataset -type d -maxdepth 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the CNN to the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We only have 10,000 images, that is not enough to make great performance results. We can either get more images or use the trick of data augmentation:\n",
    "    - Image augmentation will create many batches of our images and then each batch, it will apply some random transformation on a random selection of our images like: rotating, flipping, shifting, shearing them. Eventually, in the training process, we have more diverse images inside these batches.\n",
    "    - Image augmentation trick can help reduce overfitting.\n",
    "    - [ImageDataGenerator](https://keras.io/preprocessing/image/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 1069s - loss: 0.3867 - acc: 0.8178 - val_loss: 0.4384 - val_acc: 0.8270\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 1069s - loss: 0.1794 - acc: 0.9270 - val_loss: 0.5647 - val_acc: 0.8240\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 1068s - loss: 0.1085 - acc: 0.9579 - val_loss: 0.7012 - val_acc: 0.8261\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 1069s - loss: 0.0801 - acc: 0.9703 - val_loss: 0.7968 - val_acc: 0.8211\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 1067s - loss: 0.0638 - acc: 0.9768 - val_loss: 0.8670 - val_acc: 0.8211\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 1068s - loss: 0.0551 - acc: 0.9802 - val_loss: 0.9107 - val_acc: 0.8256\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 1067s - loss: 0.0474 - acc: 0.9831 - val_loss: 1.0068 - val_acc: 0.8128\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 1069s - loss: 0.0417 - acc: 0.9850 - val_loss: 0.9306 - val_acc: 0.8274\n",
      "Epoch 9/25\n",
      "8000/8000 [==============================] - 1068s - loss: 0.0392 - acc: 0.9861 - val_loss: 0.9454 - val_acc: 0.8234\n",
      "Epoch 10/25\n",
      "8000/8000 [==============================] - 1069s - loss: 0.0344 - acc: 0.9879 - val_loss: 1.0476 - val_acc: 0.8194\n",
      "Epoch 11/25\n",
      "8000/8000 [==============================] - 1069s - loss: 0.0318 - acc: 0.9891 - val_loss: 0.9880 - val_acc: 0.8267\n",
      "Epoch 12/25\n",
      "8000/8000 [==============================] - 1069s - loss: 0.0284 - acc: 0.9904 - val_loss: 1.1262 - val_acc: 0.8189\n",
      "Epoch 13/25\n",
      "8000/8000 [==============================] - 1069s - loss: 0.0269 - acc: 0.9907 - val_loss: 1.0884 - val_acc: 0.8300\n",
      "Epoch 14/25\n",
      "8000/8000 [==============================] - 1069s - loss: 0.0252 - acc: 0.9912 - val_loss: 1.0410 - val_acc: 0.8319\n",
      "Epoch 15/25\n",
      "8000/8000 [==============================] - 1069s - loss: 0.0234 - acc: 0.9919 - val_loss: 1.0591 - val_acc: 0.8222\n",
      "Epoch 16/25\n",
      "8000/8000 [==============================] - 1068s - loss: 0.0222 - acc: 0.9925 - val_loss: 1.1519 - val_acc: 0.8200\n",
      "Epoch 17/25\n",
      "8000/8000 [==============================] - 1070s - loss: 0.0216 - acc: 0.9927 - val_loss: 1.1189 - val_acc: 0.8292\n",
      "Epoch 18/25\n",
      "8000/8000 [==============================] - 1070s - loss: 0.0203 - acc: 0.9930 - val_loss: 1.1424 - val_acc: 0.8176\n",
      "Epoch 19/25\n",
      "8000/8000 [==============================] - 1072s - loss: 0.0192 - acc: 0.9935 - val_loss: 1.1804 - val_acc: 0.8249\n",
      "Epoch 20/25\n",
      "8000/8000 [==============================] - 1064s - loss: 0.0178 - acc: 0.9939 - val_loss: 1.2060 - val_acc: 0.8269\n",
      "Epoch 21/25\n",
      "8000/8000 [==============================] - 1064s - loss: 0.0179 - acc: 0.9940 - val_loss: 1.1506 - val_acc: 0.8290\n",
      "Epoch 22/25\n",
      "8000/8000 [==============================] - 1063s - loss: 0.0173 - acc: 0.9942 - val_loss: 1.1783 - val_acc: 0.8270\n",
      "Epoch 23/25\n",
      "8000/8000 [==============================] - 1062s - loss: 0.0170 - acc: 0.9945 - val_loss: 1.1579 - val_acc: 0.8296\n",
      "Epoch 24/25\n",
      "8000/8000 [==============================] - 1062s - loss: 0.0159 - acc: 0.9946 - val_loss: 1.1559 - val_acc: 0.8237\n",
      "Epoch 25/25\n",
      "8000/8000 [==============================] - 1064s - loss: 0.0159 - acc: 0.9946 - val_loss: 1.2083 - val_acc: 0.8229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6d24839e80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('Convolutional_Neural_Networks/dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('Convolutional_Neural_Networks/dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 8000,\n",
    "                         epochs = 25,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Making new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('Convolutional_Neural_Networks/dataset/single_prediction/cat_or_dog_1.jpg', \n",
    "                            target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    \n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Evaluation was already made during the training with the validation set, therefore k-Fold Cross Validation is not needed.\n",
    "\n",
    "Then the techniques to improve and tune a CNN model are the same as for ANNs. So here is the challenge:\n",
    "\n",
    "Apply the techniques you've learnt and use your architect power to make a CNN that will give you the gold medal:\n",
    "- Bronze medal: Test set accuracy between 80% and 85%\n",
    "- Silver medal: Test set accuracy between 85% and 90%\n",
    "- Gold medal: Test set accuracy over 90%!!\n",
    "\n",
    "Rules:\n",
    "- Use the same training set\n",
    "- Dropout allowed\n",
    "- Customized SGD allowed\n",
    "- Specific seeds not allowed\n",
    "\n",
    "\n",
    "\n",
    "## Better solution\n",
    "- [Prediction Challenge Solution - Result: 90%](https://www.udemy.com/deeplearning/learn/v4/questions/2276518)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras.api.keras.layers import Dropout\n",
    "from tensorflow.contrib.keras.api.keras.models import Sequential\n",
    "from tensorflow.contrib.keras.api.keras.layers import Conv2D\n",
    "from tensorflow.contrib.keras.api.keras.layers import MaxPooling2D\n",
    "from tensorflow.contrib.keras.api.keras.layers import Flatten\n",
    "from tensorflow.contrib.keras.api.keras.layers import Dense\n",
    "from tensorflow.contrib.keras.api.keras.callbacks import Callback\n",
    "from tensorflow.contrib.keras.api.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.contrib.keras import backend\n",
    "import os\n",
    " \n",
    " \n",
    "class LossHistory(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.epoch_id = 0\n",
    "        self.losses = ''\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses += \"Epoch {}: accuracy -> {:.4f}, val_accuracy -> {:.4f}\\n\"\\\n",
    "            .format(str(self.epoch_id), logs.get('acc'), logs.get('val_acc'))\n",
    "        self.epoch_id += 1\n",
    " \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses += 'Training begins...\\n'\n",
    " \n",
    "script_dir = os.path.dirname(__file__)\n",
    "training_set_path = os.path.join(script_dir, '../dataset/training_set')\n",
    "test_set_path = os.path.join(script_dir, '../dataset/test_set')\n",
    " \n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    " \n",
    "# Step 1 - Convolution\n",
    "input_size = (128, 128)\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(*input_size, 3), activation='relu'))\n",
    " \n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))  # 2x2 is optimal\n",
    " \n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "# Adding a third convolutional layer\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    " \n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units=64, activation='relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))\n",
    " \n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "# Part 2 - Fitting the CNN to the images\n",
    "batch_size = 32\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    " \n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    " \n",
    "training_set = train_datagen.flow_from_directory(training_set_path,\n",
    "                                                 target_size=input_size,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode='binary')\n",
    " \n",
    "test_set = test_datagen.flow_from_directory(test_set_path,\n",
    "                                            target_size=input_size,\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode='binary')\n",
    " \n",
    "# Create a loss history\n",
    "history = LossHistory()\n",
    " \n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch=8000/batch_size,\n",
    "                         epochs=90,\n",
    "                         validation_data=test_set,\n",
    "                         validation_steps=2000/batch_size,\n",
    "                         workers=12,\n",
    "                         max_q_size=100,\n",
    "                         callbacks=[history])\n",
    " \n",
    " \n",
    "# Save model\n",
    "model_backup_path = os.path.join(script_dir, '../dataset/cat_or_dogs_model.h5')\n",
    "classifier.save(model_backup_path)\n",
    "print(\"Model saved to\", model_backup_path)\n",
    " \n",
    "# Save loss history to file\n",
    "loss_history_path = os.path.join(script_dir, '../loss_history.log')\n",
    "myFile = open(loss_history_path, 'w+')\n",
    "myFile.write(history.losses)\n",
    "myFile.close()\n",
    " \n",
    "backend.clear_session()\n",
    "print(\"The model class indices are:\", training_set.class_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
